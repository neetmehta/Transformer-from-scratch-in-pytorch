{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138115e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\neetm\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\marian\\tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-en-de\")\n",
    "special_token_dict = {\"bos_token\": \"<s>\"}\n",
    "tokenizer.add_special_tokens(special_token_dict)\n",
    "\n",
    "tokenizer.encode(\"hi my name is neet\")import torch\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "\n",
    "class WMTDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, data_path, src_tokenizer, tgt_tokenizer, seq_len):\n",
    "        super().__init__()\n",
    "        self.data = pd.read_csv(data_path)\n",
    "        self.src_vocab_size = src_tokenizer.vocab_size\n",
    "        self.tgt_vocab_size = tgt_tokenizer.vocab_size\n",
    "        self.src_tokenizer = src_tokenizer\n",
    "        self.tgt_tokenizer = tgt_tokenizer\n",
    "        self.seq_len = seq_len\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        sos_token = self.src_tokenizer.encode(['<s>'])[0]\n",
    "        eos_token = self.src_tokenizer.encode(['</s>'])[0]\n",
    "        pad_token = self.src_tokenizer.encode(['<pad>'])[0]\n",
    "        src_encoding = self.src_tokenizer.encode(self.data.iloc[index]['en'])[:-1] # remove default eos token\n",
    "        tgt_encoding = self.tgt_tokenizer.encode(self.data.iloc[index]['de'])[:-1] # remove default eos token\n",
    "        print(\"len of src sen: \", len(src_encoding))\n",
    "        print(\"len of tgt sen: \", len(tgt_encoding))\n",
    "        assert len(src_encoding) < self.seq_len + 2, \"sentence too big\"\n",
    "        assert len(tgt_encoding) < self.seq_len + 2, \"sentence too big\"\n",
    "        \n",
    "        src_padding_len = self.seq_len - (len(src_encoding) + 2)  \n",
    "        tgt_padding_len = self.seq_len - (len(tgt_encoding) + 2) \n",
    "        \n",
    "        src_encoding = torch.tensor([sos_token] + src_encoding + [eos_token] + [pad_token]*src_padding_len, dtype=torch.long)\n",
    "        tgt_encoding = torch.tensor([sos_token] + tgt_encoding + [eos_token] + [pad_token]*tgt_padding_len, dtype=torch.long)\n",
    "        \n",
    "        causal_mask = torch.triu(torch.ones(self.seq_len, self.seq_len, dtype=bool), diagonal=1).to(bool)\n",
    "\n",
    "        encoder_self_attention_mask = ((src_encoding == pad_token).unsqueeze(0) | (src_encoding == pad_token).unsqueeze(1)).unsqueeze(0)\n",
    "        decoder_self_attention_mask = (tgt_encoding == pad_token).unsqueeze(0) | (tgt_encoding == pad_token).unsqueeze(1) | causal_mask\n",
    "        decoder_cross_attention_mask = (tgt_encoding == pad_token).unsqueeze(0) | (src_encoding == pad_token).unsqueeze(1)\n",
    "        \n",
    "        return src_encoding, tgt_encoding, encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask\n",
    "    \n",
    "ds = WMTDataset(\"wmt14_translate_de-en_test.csv\", tokenizer, tokenizer, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c4164a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of src sen:  30\n",
      "len of tgt sen:  48\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[False, False, False,  ...,  True,  True,  True],\n",
       "          [False, False, False,  ...,  True,  True,  True],\n",
       "          [False, False, False,  ...,  True,  True,  True],\n",
       "          ...,\n",
       "          [False, False, False,  ...,  True,  True,  True],\n",
       "          [False, False, False,  ...,  True,  True,  True],\n",
       "          [False, False, False,  ...,  True,  True,  True]]]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ea199552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0],\n",
       "        [1, 1, 1, 1]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randint(0,3, (2,1)).expand(2,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9ed983",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
